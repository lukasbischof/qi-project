{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# QSVM for AdHoc Dataset\n",
    "## Prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from qiskit import Aer\n",
    "from qiskit.algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit.providers.ibmq import least_busy\n",
    "from qiskit.utils import algorithm_globals, QuantumInstance\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit_machine_learning.kernels import QuantumKernel, FidelityQuantumKernel\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     feature_1  feature_2  label\n0     3.832743   5.277876    0.0\n1     5.906194   6.094690    0.0\n2     3.895575   5.026548    0.0\n3     2.701770   4.963716    0.0\n4     4.335398   3.895575    0.0\n..         ...        ...    ...\n995   3.330088   2.827433    1.0\n996   0.188496   2.010619    1.0\n997   1.884956   4.209734    1.0\n998   5.026548   5.780530    1.0\n999   3.518584   4.712389    1.0\n\n[1000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.832743</td>\n      <td>5.277876</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.906194</td>\n      <td>6.094690</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.895575</td>\n      <td>5.026548</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.701770</td>\n      <td>4.963716</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.335398</td>\n      <td>3.895575</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>3.330088</td>\n      <td>2.827433</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>0.188496</td>\n      <td>2.010619</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>1.884956</td>\n      <td>4.209734</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>5.026548</td>\n      <td>5.780530</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>3.518584</td>\n      <td>4.712389</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/adhoc_1k.csv', index_col=0)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 2\n"
     ]
    }
   ],
   "source": [
    "feature_dimension = df.shape[1] - 1\n",
    "print(f\"Feature dimension: {feature_dimension}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "all_features = df.copy()\n",
    "all_labels = all_features.pop('label')\n",
    "\n",
    "train = df.sample(frac=0.75, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "# Separate the features from the labels\n",
    "train_features = train.copy()\n",
    "test_features = test.copy()\n",
    "\n",
    "train_labels = train_features.pop('label')\n",
    "test_labels = test_features.pop('label')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find best SVM setting\n",
    "\n",
    "Try different kernels with different settings and plot the winning circuit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "algorithm_globals.random_seed = 42\n",
    "quantum_instance = QuantumInstance(Aer.get_backend(\"aer_simulator\"), shots=1024)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Specify kernel experiments:\n",
    "\n",
    "kernels = [\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=1, entanglement='linear')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=2, entanglement='linear')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=3, entanglement='linear')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=4, entanglement='linear')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=1, entanglement='sca')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=2, entanglement='sca')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=3, entanglement='sca')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    QuantumKernel(feature_map=(ZZFeatureMap(feature_dimension=feature_dimension, reps=4, entanglement='sca')),\n",
    "                  quantum_instance=quantum_instance),\n",
    "    # QuantumKernel(feature_map=PauliFeatureMap(feature_dimension=feature_dimension, reps=1, entanglement='linear', paulis=['ZZ']),\n",
    "    #               quantum_instance=quantum_instance),\n",
    "    # QuantumKernel(feature_map=PauliFeatureMap(feature_dimension=feature_dimension, reps=1, entanglement='linear', paulis=['Z', 'XX']),\n",
    "    #               quantum_instance=quantum_instance),\n",
    "    # QuantumKernel(feature_map=PauliFeatureMap(feature_dimension=feature_dimension, reps=2, entanglement='linear', paulis=['ZZ']),\n",
    "    #               quantum_instance=quantum_instance),\n",
    "    # QuantumKernel(feature_map=PauliFeatureMap(feature_dimension=feature_dimension, reps=2, entanglement='linear', paulis=['Z', 'XX']),\n",
    "    #               quantum_instance=quantum_instance),\n",
    "    # FidelityQuantumKernel(feature_map=ZZFeatureMap(feature_dimension=feature_dimension, reps=2, entanglement='linear'),\n",
    "    #                       fidelity=ComputeUncompute(sampler=Sampler())),\n",
    "    # FidelityQuantumKernel(feature_map=ZZFeatureMap(feature_dimension=feature_dimension, reps=3, entanglement='linear'),\n",
    "    #                       fidelity=ComputeUncompute(sampler=Sampler())),\n",
    "    # FidelityQuantumKernel(feature_map=PauliFeatureMap(feature_dimension=feature_dimension, reps=1, entanglement='linear', paulis=['Z', 'XX']),\n",
    "    #                       fidelity=ComputeUncompute(sampler=Sampler())),\n",
    "    # FidelityQuantumKernel(feature_map=PauliFeatureMap(feature_dimension=feature_dimension, reps=1, entanglement='linear', paulis=['Z', 'XX']),\n",
    "    #                       fidelity=ComputeUncompute(sampler=Sampler()))\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# svc = SVC()\n",
    "# search = RandomizedSearchCV(svc, cv=10, n_iter=16, n_jobs=-1, refit=True,\n",
    "#                             param_distributions={'kernel': [kernel.evaluate for kernel in kernels]})\n",
    "# # search.fit(train_features, train_labels)\n",
    "# search.fit(all_features, all_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# best_kernel = search.best_params_['kernel'].__self__\n",
    "# print(f\"Best is kernel {kernels.index(best_kernel)} using {best_kernel.feature_map.__class__.__name__} with {best_kernel.feature_map.reps} reps and {best_kernel.feature_map.entanglement} entanglement\")\n",
    "# svc = search.best_estimator_\n",
    "# best_kernel.feature_map.decompose().draw(output='mpl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the winning kernel circuit using 10-fold cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "best_kernel = kernels[1] # Index from output above\n",
    "svc = SVC(kernel=best_kernel.evaluate)\n",
    "\n",
    "results = cross_validate(svc, train_features, train_labels, cv=10, n_jobs=-1, return_estimator=True, return_train_score=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed for each SVC: [17877.26826859 17966.74226499 18044.72126532 18144.27726889\n",
      " 18205.86126757 18065.73526931 17976.00526857 17634.42026687\n",
      "  3183.80501127  3179.2278018 ], mean: 15027.806395316124\n"
     ]
    }
   ],
   "source": [
    "resulting_models = results['estimator']\n",
    "total_times = results['fit_time'] + results['score_time']\n",
    "print(f\"Time consumed for each SVC: {total_times}, mean: {total_times.mean()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Calculate accuracy on testing dataset\n",
    "\n",
    "accuracies = np.array([model.score(test_features, test_labels) for model in resulting_models])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00\n",
      "mean: 1.00, std: 0.00, mean training time: 15028s\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(map(lambda accuracy: f'{accuracy:.2f}', accuracies)))\n",
    "print('mean: {:.2f}, std: {:.2f}, mean training time: {:.0f}s'.format(accuracies.mean(), accuracies.std(),\n",
    "                                                                          np.array(total_times).mean()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Classical Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([0.054986  , 0.04999614, 0.04899383, 0.04899454, 0.04799461,\n        0.05399752, 0.06999612, 0.05199838, 0.03099465, 0.02798939]),\n 'score_time': array([0.01500297, 0.01500154, 0.01400256, 0.02200317, 0.0150001 ,\n        0.03199911, 0.02499986, 0.01599932, 0.00599694, 0.006001  ]),\n 'estimator': [SVC(),\n  SVC(),\n  SVC(),\n  SVC(),\n  SVC(),\n  SVC(),\n  SVC(),\n  SVC(),\n  SVC(),\n  SVC()],\n 'test_score': array([0.6       , 0.61333333, 0.53333333, 0.56      , 0.52      ,\n        0.70666667, 0.50666667, 0.72      , 0.61333333, 0.64      ]),\n 'train_score': array([0.62518519, 0.65185185, 0.64148148, 0.66222222, 0.64740741,\n        0.64148148, 0.65185185, 0.65185185, 0.64      , 0.63259259])}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical_svc = SVC(kernel='rbf')\n",
    "classical_results = cross_validate(classical_svc, train_features, train_labels, cv=10, n_jobs=-1, return_estimator=True, return_train_score=True)\n",
    "classical_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical mean SVC score: 0.6013333333333333 with std. deviation 0.06990787588756439\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classical mean SVC score: {classical_results['test_score'].mean()} with std. deviation {classical_results['test_score'].std()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57, 0.60, 0.56, 0.59, 0.56, 0.61, 0.60, 0.60, 0.56, 0.56\n",
      "mean: 0.58, std: 0.02, mean training time: 15028s\n"
     ]
    }
   ],
   "source": [
    "classical_scores = np.array([model.score(test_features, test_labels) for model in classical_results['estimator']])\n",
    "classical_total_times = results['fit_time'] + results['score_time']\n",
    "print(', '.join(map(lambda accuracy: f'{accuracy:.2f}', classical_scores)))\n",
    "print('mean: {:.2f}, std: {:.2f}, mean training time: {:.0f}s'.format(classical_scores.mean(), classical_scores.std(),\n",
    "                                                                          np.array(classical_total_times).mean()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Run on real quantum computer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2023-01-16 12:14:38,692: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen backend: ibmq_manila\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job limit reached, waiting for job 63c531adfc58051d5ff5a52d to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c531af6e244f30bfd08715 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c531b0c582e090916f4988 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c531b24366175d08ce63f9 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c56adf8eca23897127f9c8 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c56ae15876cf233d65b9c0 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c56ae3c4ff497f44906561 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c56ae419e6ff934e0496fe to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57a50fc58052a93f5a63b to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57a525876cf75bc65ba08 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57a54e90db065976938dd to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57a56c4ff4977009065aa to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57c768eca237efe27fa13 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57c785876cfdbe465ba15 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57c7ac582e0b4226f4ab3 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57c7be90db03a836938f8 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57ea6e90db0dbac69390c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57ea8fc5805176ef5a663 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57eaa436617f1bfce6523 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c57eac19e6ff06e1049763 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5809e8eca23a0fe27fa2c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c580a0e90db041b869391c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c580a18eca2343eb27fa2d to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c580a3c4ff49c89b9065cb to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5823ec4ff49559a9065d3 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c582415876cfce1f65ba38 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c582448eca231de427fa39 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5824a19e6ff06fb049777 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58439fc58059e88f5a681 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5843e0809f42cc4e1feaa to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c584415876cf91de65ba4a to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c584456e244fcd7dd0885f to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5862f5876cf6de465ba53 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c586325876cfeb9565ba54 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58635fc5805b4fbf5a695 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c586380809f4520fe1feb8 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5881afc58058827f5a6a6 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5881d4366173eb1ce6558 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58820c4ff49cce79065f3 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c588238eca232a4627fa65 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c589d8c582e09e036f4b07 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c589db5876cf0d6265ba6a to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c589de6e244f2b59d0888d to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c589e1c4ff498494906600 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58b8819e6ff74730497bf to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58b8bc4ff493cac906613 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58b8e5876cf01e865ba75 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58b906e244f7464d088a2 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58d4e19e6ff03440497ca to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58d515876cf045265ba8a to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58d54fc58053df9f5a6d4 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58d57c4ff49baeb906622 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58f1e0809f44ce2e1ff00 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58f2119e6ff3b030497dd to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58f245876cf781965ba97 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c58f27fc5805b50df5a6e5 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c590f30809f4c64ee1ff11 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c590f6e90db0611c69398f to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c590f96e244f08c8d088d0 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c590fb19e6ffd9730497ec to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c593436e244f9350d088da to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c59346c582e0d7746f4b45 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c593496e244f88aad088db to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5934de90db044e869399a to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c594f2fc580567b2f5a6f9 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c594f519e6ff9a430497fd to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c594f85876cfe24865bab2 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c594fbc4ff49389190664c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c597395876cf1e2965bac5 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5973cfc58058922f5a702 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5973f19e6ff83db04980c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c597426e244f336ed088f1 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5995a8eca23371a27fad0 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5995d8eca23162b27fad1 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c599616e244f2f95d08901 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c599654366173b45ce65b8 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a671c4ff49345990667c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a67319e6ff1175049836 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a67419e6ff76fc049837 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a6765876cfcc2e65bafb to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a83dfc58057421f5a746 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a83f6e244fbc66d08920 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a8414366171a33ce65d5 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5a8435876cff49265bb00 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5b51c6e244fda36d08942 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5b51ee90db065dd693a16 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5b51f0809f483a2e1ff94 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 63c5b52119e6ff347a049862 to finish before submitting the next one.\n"
     ]
    }
   ],
   "source": [
    "from qiskit import IBMQ\n",
    "\n",
    "# Best kernel should already be evaluated and set (in the above code cell)\n",
    "\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q')\n",
    "backend = least_busy(provider.backends(simulator=False))\n",
    "print(f\"Chosen backend: {backend}\")\n",
    "best_model = resulting_models[np.argmax(accuracies)]\n",
    "best_model.kernel.__self__.quantum_instance = QuantumInstance(backend, shots=1024)\n",
    "score = best_model.score(test_features, test_labels)\n",
    "print(f\"Quantum score: {score}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
